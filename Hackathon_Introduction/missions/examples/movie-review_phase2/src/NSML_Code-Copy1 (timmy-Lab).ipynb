{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = pd.read_csv(\"./movie_phase1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = datas['reviews']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"D:/OneDrive/GitHub/ai-hackathon-2018/missions/examples/movie-review/data/movie_review/train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:/OneDrive/GitHub/ai-hackathon-2018/missions/examples/movie-review/data/movie_review/train/train_data'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_path+\"/train_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.to_csv(base_path+\"/train_data\", index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = pd.read_csv(\"../data/movie_review/train/train_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>아련한 향수를 떠올리게 만드는 추억의 영화</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SF 코미디 영화사에서 가장 주목해야할 영화\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mv00036133의 꿈이 고스란히 담겨진 최고의 영화\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>전편을 120% 활용하는 천재적인 속편.\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1편만큼 재미있다. 3편만 조금 떨어짐. \\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>역시 전편을 능가하는 속편은 지극히 드물다\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>무슨 설명이 더 필요한가?\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mv00501003라는 이름만으로도 설레게 만드는 영화의 힘\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>이때참 ac00000559가 멋져 보였지\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>시원하면서도 심장을 꽉 조여온다.\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mv00457204에 계속해줘도 계속보게 만드는 영화\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mv00457204에 만나는 mv00390115 캐빈\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mv00457204 시즌이면 항상 가장먼저 떠오르는 가족영화\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>'둘리'와 함께 언제고 mv00457201도 즐거운 '케빈'.\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>E.T 같은 친구 한 명만 있었으면...\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>영원한 스칼렛으로 기억 될 ac00939862 \\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>록키 시리즈를 통틀어 최고!!!!\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>전개와 결말이 보였던 영화. 그래도 감동 있었던 영화.\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>별도의 수식어가 필요없는 영화. \\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>\"mv00000082 시리즈의 시작, 전설의 근원지점\"\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>\"오래된 영화ac00920758, 모든 mv00335020물의 아버지격인 영화\"\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>말이 필요없는 최고의 SF명작영화\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ac00001858 최고의 걸작은 &lt;mv00000112&gt;다!\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>끔찍했지만 정말 재밌었다. 멋진 여전사 굿!\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>자유를 향한 끝없는 집념은 없던 희망도 만들어낸다\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>현실과 이상을 넘어선 참된 교육의 표본을 보여준 영화\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>우리에겐 여전히 결핍된 참교육....\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>내 인생 최고의 영화 중 하나\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>설명이 필요없다. mv00230755. \\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>너무 길다. 그래도 대작 서사시로서의 가치는 충분하다.\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>투명 외계인이 나오는 시원시원스러운 오락물.\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520312</th>\n",
       "      <td>쩌러여\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520313</th>\n",
       "      <td>정말 잘만들었고 재밌었는데 너무 어려웠어ㅠㅠ \\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520314</th>\n",
       "      <td>정말... 감독 대박~!!!!! \\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520315</th>\n",
       "      <td>\"여운이 가시지않는 영화, 정말 오랜만이네요!\"\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520316</th>\n",
       "      <td>mv00001962년 최고의 영화다. 다시보고 싶은 명작.\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520317</th>\n",
       "      <td>mv00300916....죽인다\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520318</th>\n",
       "      <td>진짜대박....\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520319</th>\n",
       "      <td>인간이 생각하는 모든 것을 ac01200883것 같다 강추~\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520320</th>\n",
       "      <td>2시간 40분이 14분처럼 느껴졌던 영화\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520321</th>\n",
       "      <td>기발은하다. 근데 그게 전부. 하품3번했네\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520322</th>\n",
       "      <td>마지막에 반전이랄까 진짜 인줄알았는데 토템이 안멈춤\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520323</th>\n",
       "      <td>그리 생각만큼 최고는 아닌데 볼만함\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520324</th>\n",
       "      <td>정말 ac00343759퍼 놀런 감독에게 깜짝 놀랬다.\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520325</th>\n",
       "      <td>진짜 오랜만에 관객을 가지고 노는 영화.. 미친천재감독\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520326</th>\n",
       "      <td>관객의 지적 도전욕구를 일깨우는 영화 ㅎ\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520327</th>\n",
       "      <td>화려하고스토리도좋은거같애용ㅋㅋㅋ돈하나도안아까워용강추!\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520328</th>\n",
       "      <td>마지막 부분 반전 여러가지 결말을 생각하게 된 영화\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520329</th>\n",
       "      <td>기대만큼은 아니였다 ac01458291면만 놓쳐도 이해 못함..\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520330</th>\n",
       "      <td>재미 없었음\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520331</th>\n",
       "      <td>굳! 스토리에 빠져들면 지루할틈이없다\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520332</th>\n",
       "      <td>ac01161235보고도1점주는애들은못배운애들인가한심하다정말...\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520333</th>\n",
       "      <td>mv00391777를 뛰어넘을줄은 몰랐다. 단연코 걸작.\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520334</th>\n",
       "      <td>재미있지만 9점ac01175227 아닌듯..\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520335</th>\n",
       "      <td>굳 재밋다 .......\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520336</th>\n",
       "      <td>전문가 평이 맞다.. 대작은 아니여 다크나이트에 비하면\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520337</th>\n",
       "      <td>최고...\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520338</th>\n",
       "      <td>진짜 최고 ★ ★ ★ ★ ★ 감독은..대단하다..\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520339</th>\n",
       "      <td>역시 놀런 형님이다!\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520340</th>\n",
       "      <td>정말 mv00221200가 완벽한\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520341</th>\n",
       "      <td>화장실을 못갔다...... 이런 영화 간만인듯\\r\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>520342 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             아련한 향수를 떠올리게 만드는 추억의 영화\\r\\n\n",
       "0                           SF 코미디 영화사에서 가장 주목해야할 영화\\r\\n\n",
       "1                     mv00036133의 꿈이 고스란히 담겨진 최고의 영화\\r\\n\n",
       "2                             전편을 120% 활용하는 천재적인 속편.\\r\\n\n",
       "3                            1편만큼 재미있다. 3편만 조금 떨어짐. \\r\\n\n",
       "4                            역시 전편을 능가하는 속편은 지극히 드물다\\r\\n\n",
       "5                                     무슨 설명이 더 필요한가?\\r\\n\n",
       "6                  mv00501003라는 이름만으로도 설레게 만드는 영화의 힘\\r\\n\n",
       "7                             이때참 ac00000559가 멋져 보였지\\r\\n\n",
       "8                                 시원하면서도 심장을 꽉 조여온다.\\r\\n\n",
       "9                      mv00457204에 계속해줘도 계속보게 만드는 영화\\r\\n\n",
       "10                     mv00457204에 만나는 mv00390115 캐빈\\r\\n\n",
       "11                 mv00457204 시즌이면 항상 가장먼저 떠오르는 가족영화\\r\\n\n",
       "12                '둘리'와 함께 언제고 mv00457201도 즐거운 '케빈'.\\r\\n\n",
       "13                            E.T 같은 친구 한 명만 있었으면...\\r\\n\n",
       "14                        영원한 스칼렛으로 기억 될 ac00939862 \\r\\n\n",
       "15                                록키 시리즈를 통틀어 최고!!!!\\r\\n\n",
       "16                    전개와 결말이 보였던 영화. 그래도 감동 있었던 영화.\\r\\n\n",
       "17                                별도의 수식어가 필요없는 영화. \\r\\n\n",
       "18                    \"mv00000082 시리즈의 시작, 전설의 근원지점\"\\r\\n\n",
       "19      \"오래된 영화ac00920758, 모든 mv00335020물의 아버지격인 영화\"\\r\\n\n",
       "20                                말이 필요없는 최고의 SF명작영화\\r\\n\n",
       "21                 ac00001858 최고의 걸작은 <mv00000112>다!\\r\\n\n",
       "22                          끔찍했지만 정말 재밌었다. 멋진 여전사 굿!\\r\\n\n",
       "23                       자유를 향한 끝없는 집념은 없던 희망도 만들어낸다\\r\\n\n",
       "24                     현실과 이상을 넘어선 참된 교육의 표본을 보여준 영화\\r\\n\n",
       "25                              우리에겐 여전히 결핍된 참교육....\\r\\n\n",
       "26                                  내 인생 최고의 영화 중 하나\\r\\n\n",
       "27                            설명이 필요없다. mv00230755. \\r\\n\n",
       "28                    너무 길다. 그래도 대작 서사시로서의 가치는 충분하다.\\r\\n\n",
       "29                          투명 외계인이 나오는 시원시원스러운 오락물.\\r\\n\n",
       "...                                                  ...\n",
       "520312                                           쩌러여\\r\\n\n",
       "520313                     정말 잘만들었고 재밌었는데 너무 어려웠어ㅠㅠ \\r\\n\n",
       "520314                            정말... 감독 대박~!!!!! \\r\\n\n",
       "520315                    \"여운이 가시지않는 영화, 정말 오랜만이네요!\"\\r\\n\n",
       "520316              mv00001962년 최고의 영화다. 다시보고 싶은 명작.\\r\\n\n",
       "520317                             mv00300916....죽인다\\r\\n\n",
       "520318                                      진짜대박....\\r\\n\n",
       "520319             인간이 생각하는 모든 것을 ac01200883것 같다 강추~\\r\\n\n",
       "520320                        2시간 40분이 14분처럼 느껴졌던 영화\\r\\n\n",
       "520321                       기발은하다. 근데 그게 전부. 하품3번했네\\r\\n\n",
       "520322                  마지막에 반전이랄까 진짜 인줄알았는데 토템이 안멈춤\\r\\n\n",
       "520323                           그리 생각만큼 최고는 아닌데 볼만함\\r\\n\n",
       "520324                정말 ac00343759퍼 놀런 감독에게 깜짝 놀랬다.\\r\\n\n",
       "520325                진짜 오랜만에 관객을 가지고 노는 영화.. 미친천재감독\\r\\n\n",
       "520326                        관객의 지적 도전욕구를 일깨우는 영화 ㅎ\\r\\n\n",
       "520327                 화려하고스토리도좋은거같애용ㅋㅋㅋ돈하나도안아까워용강추!\\r\\n\n",
       "520328                  마지막 부분 반전 여러가지 결말을 생각하게 된 영화\\r\\n\n",
       "520329           기대만큼은 아니였다 ac01458291면만 놓쳐도 이해 못함..\\r\\n\n",
       "520330                                        재미 없었음\\r\\n\n",
       "520331                          굳! 스토리에 빠져들면 지루할틈이없다\\r\\n\n",
       "520332          ac01161235보고도1점주는애들은못배운애들인가한심하다정말...\\r\\n\n",
       "520333               mv00391777를 뛰어넘을줄은 몰랐다. 단연코 걸작.\\r\\n\n",
       "520334                      재미있지만 9점ac01175227 아닌듯..\\r\\n\n",
       "520335                                 굳 재밋다 .......\\r\\n\n",
       "520336                전문가 평이 맞다.. 대작은 아니여 다크나이트에 비하면\\r\\n\n",
       "520337                                         최고...\\r\\n\n",
       "520338                   진짜 최고 ★ ★ ★ ★ ★ 감독은..대단하다..\\r\\n\n",
       "520339                                   역시 놀런 형님이다!\\r\\n\n",
       "520340                            정말 mv00221200가 완벽한\\r\\n\n",
       "520341                     화장실을 못갔다...... 이런 영화 간만인듯\\r\\n\n",
       "\n",
       "[520342 rows x 1 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../starter/main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../starter/main.py\n",
    "# -*- coding: utf-8 -*-\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "### custom\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import codecs\n",
    "import re\n",
    "import string\n",
    "import os\n",
    "\n",
    "import pickle as pkl\n",
    "\n",
    "### NSML\n",
    "import nsml\n",
    "from nsml import DATASET_PATH, HAS_DATASET, IS_ON_NSML\n",
    "from dataset import MovieReviewDataset, preprocess\n",
    "\n",
    "# DONOTCHANGE: They are reserved for nsml\n",
    "# This is for nsml leaderboard\n",
    "def bind_model(sess, config):\n",
    "    # 학습한 모델을 저장하는 함수입니다.\n",
    "    def save(dir_name, *args):\n",
    "        # directory\n",
    "        os.makedirs(dir_name, exist_ok=True)\n",
    "        saver = tf.train.Saver()\n",
    "        saver.save(sess, os.path.join(dir_name, 'model'))\n",
    "#         print(\"{} is saved on nsml\".format(os.path.join(dir_name, 'model')))\n",
    "#         with open(os.path.join(dir_name, 'dataset.pkl'), 'wb') as f:\n",
    "#             pkl.dump(dataset, f)\n",
    "#             print(\"dataset is saved on nsml\")\n",
    "\n",
    "    # 저장한 모델을 불러올 수 있는 함수입니다.\n",
    "    def load(dir_name, *args):\n",
    "        saver = tf.train.Saver()\n",
    "        # find checkpoint\n",
    "        ckpt = tf.train.get_checkpoint_state(dir_name)\n",
    "        if ckpt and ckpt.model_checkpoint_path:\n",
    "            checkpoint = os.path.basename(ckpt.model_checkpoint_path)\n",
    "            saver.restore(sess, os.path.join(dir_name, checkpoint))\n",
    "#             with open(os.path.join(dir_name, 'dataset.pkl'), 'rb') as f:\n",
    "#                 dataset = pkl.load(f)\n",
    "        else:\n",
    "            raise NotImplemented('No checkpoint!')\n",
    "        print('Model loaded')\n",
    "\n",
    "    def infer(raw_data, **kwargs):\n",
    "        \"\"\"\n",
    "        :param raw_data: raw input (여기서는 문자열)을 입력받습니다\n",
    "        :param kwargs:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "#         preprocessed_data = dataset.preprocess(raw_data)\n",
    "#         embedded_data = dataset.test_embedding(raw_data)\n",
    "        embedded_data = preprocess(raw_data, config.strmaxlen)\n",
    "    \n",
    "        # 저장한 모델에 입력값을 넣고 prediction 결과를 리턴받습니다\n",
    "        pred = sess.run(output, feed_dict={x: embedded_data})\n",
    "        point = pred.squeeze(axis=1).tolist()\n",
    "        print(np.shape(point))\n",
    "        # DONOTCHANGE: They are reserved for nsml\n",
    "        # 리턴 결과는 [(확률, 0 or 1)] 의 형태로 보내야만 리더보드에 올릴 수 있습니다. 리더보드 결과에 확률의 값은 영향을 미치지 않습니다\n",
    "        return list(zip(np.zeros(len(point)), point))\n",
    "    \n",
    "    # DONOTCHANGE: They are reserved for nsml\n",
    "    # nsml에서 지정한 함수에 접근할 수 있도록 하는 함수입니다.\n",
    "    nsml.bind(save=save, load=load, infer=infer)\n",
    "\n",
    "def _batch_loader(iterable, n=1):\n",
    "    \"\"\"\n",
    "    데이터를 배치 사이즈만큼 잘라서 보내주는 함수입니다. PyTorch의 DataLoader와 같은 역할을 합니다\n",
    "\n",
    "    :param iterable: 데이터 list, 혹은 다른 포맷\n",
    "    :param n: 배치 사이즈\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    length = len(iterable)\n",
    "    for n_idx in range(0, length, n):\n",
    "        yield iterable[n_idx:min(n_idx + n, length)]\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "        \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    args = argparse.ArgumentParser()\n",
    "    # DONOTCHANGE: They are reserved for nsml\n",
    "    args.add_argument('--mode', type=str, default='train')\n",
    "    args.add_argument('--pause', type=int, default=0)\n",
    "    args.add_argument('--iteration', type=str, default='0')\n",
    "\n",
    "    # User options\n",
    "    args.add_argument('--output', type=int, default=1)\n",
    "    args.add_argument('--epochs', type=int, default=5)\n",
    "    args.add_argument('--strmaxlen', type=int, default=400)\n",
    "    \n",
    "    args.add_argument('--maxlen', type=int, default=400)\n",
    "    args.add_argument('--cell_size', type=int, default=40)\n",
    "    args.add_argument('--embed_size', type=int, default=300)\n",
    "    args.add_argument('--prob_dropout', type=float, default=0.4)\n",
    "    args.add_argument('--max_features', type=int, default=431)\n",
    "    args.add_argument('--batch_size', type=int, default=256)\n",
    "    \n",
    "    config = args.parse_args()\n",
    " \n",
    "\n",
    "    if not HAS_DATASET and not IS_ON_NSML:  # It is not running on nsml\n",
    "        DATASET_PATH = '../sample_data/movie_review/'\n",
    "\n",
    "     # 모델의 specification\n",
    "    input_size = config.embed_size*config.maxlen\n",
    "    output_size = 1\n",
    "    hidden_layer_size = 200\n",
    "    learning_rate = 0.001\n",
    "    character_size = 251\n",
    "    emb_train = True\n",
    "\n",
    "    x = tf.placeholder(tf.int32, [None, config.maxlen])\n",
    "    y_ = tf.placeholder(tf.float32, [None, output_size])\n",
    "    \n",
    "    # 임베딩\n",
    "    word_embedding = tf.get_variable('word_embedding', [config.max_features, config.embed_size])\n",
    "    embedded = tf.nn.embedding_lookup(word_embedding, x)\n",
    "\n",
    "    # 첫 번째 레이어\n",
    "    first_layer_weight = weight_variable([input_size, hidden_layer_size])\n",
    "    first_layer_bias = bias_variable([hidden_layer_size])\n",
    "    hidden_layer = tf.matmul(tf.reshape(embedded, (-1, input_size)), first_layer_weight) + first_layer_bias\n",
    "\n",
    "    # 두 번째 (아웃풋) 레이어\n",
    "    second_layer_weight = weight_variable([hidden_layer_size, output_size])\n",
    "    second_layer_bias = bias_variable([output_size])\n",
    "    output = tf.matmul(hidden_layer, second_layer_weight) + second_layer_bias\n",
    "#     output_sigmoid = tf.sigmoid(output)\n",
    "\n",
    "    # loss와 optimizer\n",
    "    loss_mse = tf.losses.mean_squared_error(y_, output)\n",
    "    train_step = tf.train.AdamOptimizer(learning_rate).minimize(loss_mse)\n",
    "\n",
    "    sess = tf.InteractiveSession()\n",
    "    tf.global_variables_initializer().run()\n",
    "        \n",
    "    # DONOTCHANGE: Reserved for nsml\n",
    "    dataset = MovieReviewDataset(DATASET_PATH, config.strmaxlen)\n",
    "#     dataset.dset_regex_morph(morph=True)\n",
    "#     dataset.dset_embedding()\n",
    "    bind_model(sess=sess, config=config)\n",
    "\n",
    "   \n",
    "    # DONOTCHANGE: Reserved for nsml\n",
    "    if config.pause:\n",
    "        nsml.paused(scope=locals())\n",
    "    \n",
    "    if config.mode == 'train':\n",
    "#         dataset = MovieReviewDataset(DATASET_PATH, config.strmaxlen)\n",
    "#         dataset.dset_regex_morph(morph=True)\n",
    "#         dataset.dset_embedding()\n",
    "        \n",
    "\n",
    "        \n",
    "        ### csutom\n",
    "#         dataset.dset_regex_morph(morph=True)\n",
    "#         emb_path=\"D:/onedrive/code/ipython/wordvec/pre_trained/fasttext/ko/wiki.ko.vec\"\n",
    "#         dataset.load_emb_model(embedding_path=emb_path)\n",
    "#         dataset.dset_embedding(dataset.emb_model)\n",
    "#         dataset.dset_embedding()\n",
    "        \n",
    "        dataset_len = len(dataset)\n",
    "        one_batch_size = dataset_len//config.batch_size\n",
    "        if dataset_len % config.batch_size != 0:\n",
    "            one_batch_size += 1\n",
    "        # epoch마다 학습을 수행합니다.\n",
    "        for epoch in range(config.epochs):\n",
    "            avg_loss = 0.0\n",
    "            for i, (data, labels) in enumerate(_batch_loader(dataset, config.batch_size)):\n",
    "                _, loss = sess.run([train_step, loss_mse],\n",
    "                                   feed_dict={x: data, y_: labels})\n",
    "#                 print('Batch : ', i + 1, '/', one_batch_size,\n",
    "#                       ', BCE in this minibatch: ', float(loss))\n",
    "                avg_loss += float(loss)\n",
    "            print('epoch:', epoch, ' train_loss:', float(avg_loss/one_batch_size))\n",
    "            nsml.report(summary=True, scope=locals(), epoch=epoch, epoch_total=config.epochs,\n",
    "                        train__loss=float(avg_loss/one_batch_size), step=epoch)\n",
    "            # DONOTCHANGE (You can decide how often you want to save the model)\n",
    "            nsml.save(epoch)\n",
    "\n",
    "    # 로컬 테스트 모드일때 사용합니다\n",
    "    # 결과가 아래와 같이 나온다면, nsml submit을 통해서 제출할 수 있습니다.\n",
    "    # [(0.3, 0), (0.7, 1), ... ]\n",
    "    elif config.mode == 'test_local':\n",
    "        with open(os.path.join(DATASET_PATH, 'test/test_data'), 'rt', encoding='utf-8') as f:\n",
    "            reviews = f.readlines()\n",
    "        res = []\n",
    "        for batch in _batch_loader(reviews, config.batch_size):\n",
    "            temp_res = nsml.infer(batch)\n",
    "            res += temp_res\n",
    "#         res = nsml.infer(reviews)\n",
    "        print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  train_loss: 118.17220306396484\n",
      "epoch: 1  train_loss: 4420.47900390625\n",
      "epoch: 2  train_loss: 319.73101806640625\n",
      "epoch: 3  train_loss: 829.7860107421875\n",
      "epoch: 4  train_loss: 2231.032958984375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-04-03 21:16:15.717569: I C:\\tf_jenkins\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\platform\\cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\n",
      "2018-04-03 21:16:16.031441: I C:\\tf_jenkins\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1212] Found device 0 with properties: \n",
      "name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.683\n",
      "pciBusID: 0000:01:00.0\n",
      "totalMemory: 11.00GiB freeMemory: 9.09GiB\n",
      "2018-04-03 21:16:16.031763: I C:\\tf_jenkins\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1312] Adding visible gpu devices: 0\n",
      "2018-04-03 21:16:16.648086: I C:\\tf_jenkins\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8806 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "!python ../starter/main.py --mode train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87,)\n",
      "[(0.0, -1.0029360055923462), (0.0, -0.5922660827636719), (0.0, -0.5258321762084961), (0.0, -0.46770694851875305), (0.0, -0.9856932163238525), (0.0, 0.17409417033195496), (0.0, -1.0555821657180786), (0.0, -0.9003530740737915), (0.0, -1.25115966796875), (0.0, -0.8233543634414673), (0.0, -0.454477459192276), (0.0, -1.193847417831421), (0.0, -0.004324875771999359), (0.0, -0.9096697568893433), (0.0, -0.23301494121551514), (0.0, -0.6798992156982422), (0.0, -0.9385336637496948), (0.0, 0.20161789655685425), (0.0, -0.6412708759307861), (0.0, -1.9880775213241577), (0.0, -0.6272163391113281), (0.0, -0.5542000532150269), (0.0, -0.5005652904510498), (0.0, -0.42831066250801086), (0.0, 0.4964554011821747), (0.0, -0.6084188222885132), (0.0, -1.38687264919281), (0.0, -0.5787463188171387), (0.0, -2.1129531860351562), (0.0, -0.3341926038265228), (0.0, -1.610254168510437), (0.0, -1.316604733467102), (0.0, 0.0038783326745033264), (0.0, 0.6582373380661011), (0.0, -1.1776357889175415), (0.0, -0.21557018160820007), (0.0, -0.4540349543094635), (0.0, -0.8899532556533813), (0.0, -1.1772528886795044), (0.0, -0.589270830154419), (0.0, -1.2657780647277832), (0.0, -1.0944963693618774), (0.0, -0.269546777009964), (0.0, -0.7613799571990967), (0.0, -0.8739781379699707), (0.0, -0.8732295036315918), (0.0, -0.32393908500671387), (0.0, -0.4817609488964081), (0.0, -0.5272475481033325), (0.0, -1.1202242374420166), (0.0, 0.1692580282688141), (0.0, -0.8525235056877136), (0.0, -0.7941698431968689), (0.0, -0.9751657247543335), (0.0, -0.19394001364707947), (0.0, -0.7400272488594055), (0.0, -0.5845773816108704), (0.0, -0.6199964284896851), (0.0, -0.36087480187416077), (0.0, -0.0714925155043602), (0.0, -0.615979790687561), (0.0, -0.22929587960243225), (0.0, -0.5281720161437988), (0.0, -2.1663765907287598), (0.0, 0.24768027663230896), (0.0, -0.5579814910888672), (0.0, 0.034176625311374664), (0.0, 0.29490241408348083), (0.0, -0.42823806405067444), (0.0, -0.9151004552841187), (0.0, -0.418430894613266), (0.0, 0.252248078584671), (0.0, -0.9105356931686401), (0.0, -0.7554827928543091), (0.0, -0.11407818645238876), (0.0, 0.3962583839893341), (0.0, -0.14480659365653992), (0.0, -0.37320223450660706), (0.0, 0.2893032133579254), (0.0, -0.5939229130744934), (0.0, -1.886802077293396), (0.0, -1.1097495555877686), (0.0, -0.5962474346160889), (0.0, -1.1573292016983032), (0.0, -0.6542625427246094), (0.0, 0.30222973227500916), (0.0, -0.6819044351577759)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-04-03 21:16:20.067405: I C:\\tf_jenkins\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\platform\\cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\n",
      "2018-04-03 21:16:20.373957: I C:\\tf_jenkins\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1212] Found device 0 with properties: \n",
      "name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.683\n",
      "pciBusID: 0000:01:00.0\n",
      "totalMemory: 11.00GiB freeMemory: 9.09GiB\n",
      "2018-04-03 21:16:20.374311: I C:\\tf_jenkins\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1312] Adding visible gpu devices: 0\n",
      "2018-04-03 21:16:20.953064: I C:\\tf_jenkins\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8806 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "!python ../starter/main.py --mode test_local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch :  1 / 1 , MSE in this minibatch:  19.29180335998535\n",
      "epoch: 0  train_loss: 19.29180335998535\n",
      "Batch :  1 / 1 , MSE in this minibatch:  7.607476711273193\n",
      "epoch: 1  train_loss: 7.607476711273193\n",
      "Batch :  1 / 1 , MSE in this minibatch:  7.607476711273193\n",
      "epoch: 2  train_loss: 7.607476711273193\n",
      "Batch :  1 / 1 , MSE in this minibatch:  7.607476711273193\n",
      "epoch: 3  train_loss: 7.607476711273193\n",
      "Batch :  1 / 1 , MSE in this minibatch:  7.607476711273193\n",
      "epoch: 4  train_loss: 7.607476711273193\n",
      "Batch :  1 / 1 , MSE in this minibatch:  7.607476711273193\n",
      "epoch: 5  train_loss: 7.607476711273193\n",
      "Batch :  1 / 1 , MSE in this minibatch:  7.607476711273193\n",
      "epoch: 6  train_loss: 7.607476711273193\n",
      "Batch :  1 / 1 , MSE in this minibatch:  7.607476711273193\n",
      "epoch: 7  train_loss: 7.607476711273193\n",
      "Batch :  1 / 1 , MSE in this minibatch:  7.607476711273193\n",
      "epoch: 8  train_loss: 7.607476711273193\n",
      "Batch :  1 / 1 , MSE in this minibatch:  7.607476711273193\n",
      "epoch: 9  train_loss: 7.607476711273193\n"
     ]
    }
   ],
   "source": [
    "!python ../example_back/main.py --mode train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = [(0.0, 5.507122039794922), (0.0, 5.477208137512207), (0.0, 5.081559658050537), (0.0, 5.745182037353516), (0.0, 6.0997090339660645), (0.0, 5.659692287445068), (0.0, 5.920278072357178), (0.0, 6.350973606109619), (0.0, 5.890348434448242), (0.0, 5.882244110107422), (0.0, 5.47745418548584), (0.0, 5.883562088012695), (0.0, 5.641011714935303), (0.0, 4.899208068847656), (0.0, 5.4042487144470215), (0.0, 5.44482421875), (0.0, 5.365687847137451), (0.0, 5.508814334869385), (0.0, 5.610958576202393), (0.0, 6.146960735321045), (0.0, 5.443153381347656), (0.0, 5.225772857666016), (0.0, 5.609511852264404), (0.0, 5.245474338531494), (0.0, 5.728208065032959), (0.0, 5.431302547454834), (0.0, 5.909133434295654), (0.0, 5.599045753479004), (0.0, 5.0513811111450195), (0.0, 5.178066253662109), (0.0, 5.482705593109131), (0.0, 5.959336280822754), (0.0, 5.443247318267822), (0.0, 5.457961559295654), (0.0, 5.3761372566223145), (0.0, 5.327464580535889), (0.0, 4.982173919677734), (0.0, 4.972344398498535), (0.0, 5.525853157043457), (0.0, 5.402675628662109), (0.0, 5.452371597290039), (0.0, 5.296295166015625), (0.0, 5.418962001800537), (0.0, 5.954452991485596), (0.0, 5.593425273895264), (0.0, 5.549355983734131), (0.0, 5.962398529052734), (0.0, 5.473674297332764), (0.0, 5.136119365692139), (0.0, 5.7232985496521), (0.0, 5.20017671585083), (0.0, 4.964993476867676), (0.0, 5.232919692993164), (0.0, 5.040822505950928), (0.0, 5.335686206817627), (0.0, 5.714105606079102), (0.0, 5.286571502685547), (0.0, 5.32389497756958), (0.0, 6.3306097984313965), (0.0, 5.624547958374023), (0.0, 5.531543254852295), (0.0, 5.307179927825928), (0.0, 5.559380531311035), (0.0, 5.755814075469971), (0.0, 5.190467357635498), (0.0, 5.5357513427734375), (0.0, 5.294408798217773), (0.0, 5.54160213470459), (0.0, 5.4538254737854), (0.0, 5.685484409332275), (0.0, 5.525065898895264), (0.0, 5.39377498626709), (0.0, 5.509948253631592), (0.0, 5.330820083618164), (0.0, 5.601436138153076), (0.0, 5.052368640899658), (0.0, 5.631039142608643), (0.0, 6.053228378295898), (0.0, 5.571783542633057), (0.0, 5.3911824226379395), (0.0, 5.865889549255371), (0.0, 5.761862754821777), (0.0, 5.490329742431641), (0.0, 5.48750638961792), (0.0, 4.960508346557617), (0.0, 5.481670379638672), (0.0, 5.939573764801025), (0.0, 5.222892761230469), (0.0, 5.459935665130615), (0.0, 5.423129081726074), (0.0, 5.0208635330200195), (0.0, 5.444896221160889), (0.0, 5.56053352355957), (0.0, 5.544216156005859), (0.0, 5.691243648529053), (0.0, 5.1534810066223145), (0.0, 5.399294376373291), (0.0, 5.101796627044678), (0.0, 5.719296455383301), (0.0, 5.345041751861572), (0.0, 5.30886697769165), (0.0, 5.01315450668335), (0.0, 5.454311847686768), (0.0, 5.488786220550537), (0.0, 5.514221668243408), (0.0, 5.336738109588623), (0.0, 5.635279655456543)]\n",
    "tmp2 = [(0.0, 0.17151004076004028), (0.0, 0.3102037310600281), (0.0, 0.8511660695075989), (0.0, 0.11610407382249832), (0.0, 0.37960124015808105), (0.0, 0.49174389243125916), (0.0, 1.0346283912658691), (0.0, 0.9915686845779419), (0.0, 0.08578527718782425), (0.0, 1.8068877458572388), (0.0, 0.8327751755714417), (0.0, 0.650511622428894), (0.0, 0.41550737619400024), (0.0, 0.6187836527824402), (0.0, -0.13442781567573547), (0.0, 1.1096271276474), (0.0, 0.1299227476119995), (0.0, 0.7282607555389404), (0.0, 0.5944207906723022), (0.0, 1.1815965175628662), (0.0, -0.919247031211853), (0.0, 1.716301679611206), (0.0, 1.3576778173446655), (0.0, 0.6849305033683777), (0.0, 0.3809773325920105), (0.0, 0.7658463716506958), (0.0, 1.1667943000793457), (0.0, 1.3709861040115356), (0.0, 0.9598567485809326), (0.0, 0.8689199686050415), (0.0, 0.26576030254364014), (0.0, 0.5343411564826965), (0.0, 0.5739362835884094), (0.0, 0.2807602882385254), (0.0, 0.6746336817741394), (0.0, 0.5748001933097839), (0.0, 0.7115890383720398), (0.0, 0.9866825938224792), (0.0, 1.0107001066207886), (0.0, 0.45365607738494873), (0.0, 1.1045211553573608), (0.0, 0.02827710658311844), (0.0, 0.5486428141593933), (0.0, 0.2230035364627838), (0.0, 1.0092824697494507), (0.0, 0.8335793018341064), (0.0, 0.7652144432067871), (0.0, 0.8846083879470825), (0.0, 0.25722795724868774), (0.0, 0.023475296795368195), (0.0, 1.0517147779464722), (0.0, 0.8199621438980103), (0.0, 0.17542585730552673), (0.0, 0.9163600206375122), (0.0, 0.5567643046379089), (0.0, 1.1359342336654663), (0.0, 0.21362942457199097), (0.0, 0.09889668971300125), (0.0, 0.4078075587749481), (0.0, 0.7591463327407837), (0.0, 0.4542941749095917), (0.0, 0.39212343096733093), (0.0, 0.42554154992103577), (0.0, 0.8650057315826416), (0.0, 1.1026344299316406), (0.0, 1.3823593854904175), (0.0, 0.6251580715179443), (0.0, 0.38394099473953247), (0.0, 0.5180602669715881), (0.0, -0.3579539954662323), (0.0, 0.12424284964799881), (0.0, 0.8763779401779175), (0.0, 0.35700929164886475), (0.0, 0.5003722310066223), (0.0, 0.11724204570055008), (0.0, 0.5098779201507568), (0.0, 0.5466137528419495), (0.0, 0.28781092166900635), (0.0, -0.4003223478794098), (0.0, 1.2976845502853394), (0.0, 0.3018210232257843), (0.0, 2.049747943878174), (0.0, 0.46604761481285095), (0.0, 0.7953343987464905), (0.0, 0.6959224939346313), (0.0, 1.383487582206726), (0.0, -0.5519022941589355)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107, 2)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = [5.849471092224121, 4.6791486740112305, 5.030023574829102, 4.490840435028076, 5.456708908081055, 5.024709701538086, 5.023854732513428, 5.876331329345703, 4.961490631103516, 5.1269001960754395, 4.586499214172363, 5.601384162902832, 5.2715301513671875, 5.52301549911499, 5.54022216796875, 5.463802337646484, 5.524343013763428, 5.513424873352051, 5.404085159301758, 5.085888862609863, 5.18102502822876, 4.819967269897461, 4.992971897125244, 5.379040241241455, 5.407474994659424, 5.209883213043213, 5.179623126983643, 4.9488115310668945, 5.008663177490234, 4.976510047912598, 4.887200355529785, 5.230838298797607, 4.875622272491455, 5.012160778045654, 4.959322929382324, 4.795332908630371, 5.235421657562256, 5.2926201820373535, 5.035041809082031, 5.089512825012207, 4.789463043212891, 5.048935413360596, 4.758528709411621, 5.34534215927124, 5.352360725402832, 4.331325531005859, 4.898258209228516, 5.234723091125488, 5.124054908752441, 5.020263195037842, 4.730261325836182, 4.833620071411133, 5.053152561187744, 5.565540790557861, 5.36036491394043, 5.275566577911377, 4.7412919998168945, 4.223257541656494, 4.780771255493164, 5.20416784286499, 4.944936275482178, 5.273554801940918, 4.920029640197754, 5.362622261047363, 4.745726585388184, 5.217639923095703, 5.082106113433838, 4.781542778015137, 4.717349052429199, 5.029264450073242, 5.311281681060791, 4.725761413574219, 5.068767070770264, 5.286892414093018, 4.738636493682861, 4.955305099487305, 4.970938682556152, 5.201949596405029, 4.973832130432129, 5.466550350189209, 4.975394248962402, 4.786642074584961, 5.051764965057373, 4.621184349060059, 5.357519149780273, 4.947997093200684, 4.799294471740723, 4.8324103355407715, 5.573225498199463, 4.858403205871582, 5.014888286590576, 5.209362030029297, 4.926170825958252, 4.9326958656311035, 4.597771167755127, 4.772767066955566, 4.680015563964844, 4.746307373046875, 5.023454666137695, 4.613122940063477, 5.03616189956665, 4.5199127197265625, 4.76422119140625, 4.486040115356445, 4.875519275665283, 4.937893867492676, 5.213864803314209]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.849471092224121, 4.6791486740112305, 5.030023574829102, 4.490840435028076, 5.456708908081055, 5.024709701538086, 5.023854732513428, 5.876331329345703, 4.961490631103516, 5.1269001960754395, 4.586499214172363, 5.601384162902832, 5.2715301513671875, 5.52301549911499, 5.54022216796875, 5.463802337646484, 5.524343013763428, 5.513424873352051, 5.404085159301758, 5.085888862609863, 5.18102502822876, 4.819967269897461, 4.992971897125244, 5.379040241241455, 5.407474994659424, 5.209883213043213, 5.179623126983643, 4.9488115310668945, 5.008663177490234, 4.976510047912598, 4.887200355529785, 5.230838298797607, 4.875622272491455, 5.012160778045654, 4.959322929382324, 4.795332908630371, 5.235421657562256, 5.2926201820373535, 5.035041809082031, 5.089512825012207, 4.789463043212891, 5.048935413360596, 4.758528709411621, 5.34534215927124, 5.352360725402832, 4.331325531005859, 4.898258209228516, 5.234723091125488, 5.124054908752441, 5.020263195037842, 4.730261325836182, 4.833620071411133, 5.053152561187744, 5.565540790557861, 5.36036491394043, 5.275566577911377, 4.7412919998168945, 4.223257541656494, 4.780771255493164, 5.20416784286499, 4.944936275482178, 5.273554801940918, 4.920029640197754, 5.362622261047363, 4.745726585388184, 5.217639923095703, 5.082106113433838, 4.781542778015137, 4.717349052429199, 5.029264450073242, 5.311281681060791, 4.725761413574219, 5.068767070770264, 5.286892414093018, 4.738636493682861, 4.955305099487305, 4.970938682556152, 5.201949596405029, 4.973832130432129, 5.466550350189209, 4.975394248962402, 4.786642074584961, 5.051764965057373, 4.621184349060059, 5.357519149780273, 4.947997093200684, 4.799294471740723, 4.8324103355407715, 5.573225498199463, 4.858403205871582, 5.014888286590576, 5.209362030029297, 4.926170825958252, 4.9326958656311035, 4.597771167755127, 4.772767066955566, 4.680015563964844, 4.746307373046875, 5.023454666137695, 4.613122940063477, 5.03616189956665, 4.5199127197265625, 4.76422119140625, 4.486040115356445, 4.875519275665283, 4.937893867492676, 5.213864803314209]\n"
     ]
    }
   ],
   "source": [
    "!python ../example_back/main.py --mode test_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../starter/Dataset.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../starter/Dataset.py\n",
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import codecs\n",
    "import re\n",
    "import string\n",
    "import os\n",
    "\n",
    "#===============keras ==============\n",
    "from keras.preprocessing import text, sequence\n",
    "\n",
    "#===============morphnizer ============\n",
    "# from konlpy.tag import Twitter\n",
    "# twt = Twitter()\n",
    "\n",
    "class MovieReviewDataset():\n",
    "    \"\"\"\n",
    "    영화리뷰 데이터를 읽어서, tuple (데이터, 레이블)의 형태로 리턴하는 파이썬 오브젝트 입니다.\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset_path: str, max_length: int):\n",
    "        \"\"\"\n",
    "        initializer\n",
    "        :param dataset_path: 데이터셋 root path\n",
    "        :param max_length: 문자열의 최대 길이\n",
    "        \"\"\"\n",
    "\n",
    "        # 데이터, 레이블 각각의 경로\n",
    "        data_review = os.path.join(dataset_path, 'train', 'train_data')\n",
    "        data_label = os.path.join(dataset_path, 'train', 'train_label')\n",
    "\n",
    "        # 영화리뷰 데이터를 읽고 preprocess까지 진행합니다\n",
    "        with open(data_review, 'rt', encoding='utf-8') as f:\n",
    "            self.reviews = f.readlines()\n",
    "        # 영화리뷰 레이블을 읽고 preprocess까지 진행합니다.\n",
    "        with open(data_label) as f:\n",
    "            self.labels = [np.float32(x) for x in f.readlines()]\n",
    "            \n",
    "        self.dset = pd.DataFrame(data=np.array([self.reviews, self.labels]).T, columns=['reviews', 'labels'])\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "\n",
    "        :return: 전체 데이터의 수를 리턴합니다\n",
    "        \"\"\"\n",
    "        return len(self.reviews)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "\n",
    "        :param idx: 필요한 데이터의 인덱스\n",
    "        :return: 인덱스에 맞는 데이터, 레이블 pair를 리턴합니다\n",
    "        \"\"\"\n",
    "        return self.reviews[idx], self.labels[idx]\n",
    "    \n",
    "    def export(self):\n",
    "        self.dset.to_csv(\"./export.csv\")\n",
    "        \n",
    "    def prin(self):\n",
    "        print(self.dset)   \n",
    "\n",
    "    def load_emb_model(self, embedding_path, encodings = \"utf-8\"):\n",
    "        def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "        self.emb_model = dict(get_coefs(*o.strip().split(\" \")) for o in codecs.open(embedding_path, \"r\", encodings ))\n",
    "    \n",
    "    def preprocess(self, raw_data, morph=True):\n",
    "        docs = []\n",
    "        for doc in raw_data:\n",
    "            doc = re.sub('[^\\w?!]', ' ', doc)\n",
    "            doc = re.sub('[\\s]+', ' ', doc)\n",
    "            doc = re.sub('[\\s]$|^[\\s]', '', doc)\n",
    "#             if morph:\n",
    "#                 docs.append(\" \".join(twt.morphs(doc)))\n",
    "#             else:\n",
    "#                 docs.append(doc)\n",
    "            docs.append(doc)\n",
    "        return docs\n",
    "    \n",
    "    def test_embedding(self, raw_data,\n",
    "#                        emb_model,\n",
    "                       embed_size = 300,\n",
    "                       max_features = 100000,\n",
    "                       maxlen = 20,\n",
    "                       oov_zero = True,\n",
    "                       truncating='pre'\n",
    "                      ):\n",
    "        \n",
    "\n",
    "        list_sentences = raw_data \n",
    "        list_tokenized = self.tokenizer.texts_to_sequences(list_sentences)\n",
    "        X = sequence.pad_sequences(list_tokenized, maxlen=maxlen, truncating=truncating)\n",
    "        return X\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def dset_regex_morph(self, morph=True):\n",
    "        docs = []\n",
    "        for doc in self.dset['reviews']:\n",
    "            doc = re.sub('[^\\w?!]', ' ', doc)\n",
    "            doc = re.sub('[\\s]+', ' ', doc)\n",
    "            doc = re.sub('[\\s]$|^[\\s]', '', doc)\n",
    "#             if morph:\n",
    "#                 docs.append(\" \".join(twt.morphs(doc)))\n",
    "#             else:\n",
    "#                 docs.append(doc)\n",
    "            docs.append(doc)\n",
    "        self.dset['reviews'] = docs\n",
    "    \n",
    "    def dset_embedding(self,\n",
    "#                        emb_model,\n",
    "                       embed_size = 300,\n",
    "                       max_features = 100000,\n",
    "                       maxlen = 20,\n",
    "                       oov_zero = True,\n",
    "                       truncating='pre'\n",
    "                      ):\n",
    "        \n",
    "        doc_column = \"reviews\"\n",
    "        list_classes = [\"labels\"]\n",
    "\n",
    "        list_sentences = self.dset[doc_column].fillna('UNK').values.tolist()\n",
    "        \n",
    "\n",
    "        self.tokenizer = text.Tokenizer(num_words =max_features)\n",
    "        self.tokenizer.fit_on_texts(list_sentences)\n",
    "\n",
    "        list_tokenized = self.tokenizer.texts_to_sequences(list_sentences)\n",
    "        \n",
    "        X = sequence.pad_sequences(list_tokenized, maxlen=maxlen, truncating=truncating)\n",
    "        Y = self.dset[list_classes].values\n",
    "        print(\"=== Data is preprocessed\")\n",
    "\n",
    "#         word_index = tokenizer.word_index\n",
    "#         nb_words = min(max_features, len(word_index))\n",
    "\n",
    "#         if oov_zero:\n",
    "#             embedding_matrix = np.zeros((nb_words, embed_size))\n",
    "#         else:\n",
    "#             embedding_matrix = np.random.normal(0.001, 0.4, (nb_words, embed_size))\n",
    "\n",
    "#         for word, i in word_index.items():\n",
    "#             if i >= max_features: continue\n",
    "#             try:\n",
    "#                 embedding_vector = emb_model.get(word)\n",
    "#                 if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "#             except: \n",
    "#                 pass\n",
    "#         print(\"=== Embedding Matrix is loaded\")\n",
    "        \n",
    "        self.reviews = X\n",
    "        self.labels = Y\n",
    "#         self.emb_matrix = embedding_matrix\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
